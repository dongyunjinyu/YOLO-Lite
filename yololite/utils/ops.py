# YOLO-Lite ğŸš€
"""çŒ´å­è¡¥ä¸ï¼Œç”¨äºæ›´æ–°/æ‰©å±•ç°æœ‰å‡½æ•°çš„åŠŸèƒ½ã€‚"""

import contextlib
import math
import re
import time

import cv2
import numpy as np
import torch
import torch.nn.functional as F

from yololite.utils import LOGGER
from yololite.utils.metrics import batch_probiou


class Profile(contextlib.ContextDecorator):
    """
    YOLOv8 Profile ç±»ã€‚å¯ä»¥ä½œä¸ºè£…é¥°å™¨ @Profile() ä½¿ç”¨ï¼Œæˆ–ä½œä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨ 'with Profile():'ã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from yololite.utils.ops import Profile

        with Profile(device=device) as dt:
            pass  # è¿™é‡Œæ˜¯æ…¢æ“ä½œ

        print(dt)  # è¾“å‡º "Elapsed time is 9.5367431640625e-07 s"
        ```
    """

    def __init__(self, t=0.0, device: torch.device = None):
        """
        åˆå§‹åŒ– Profile ç±»ã€‚

        å‚æ•°ï¼š
            t (float): åˆå§‹æ—¶é—´ã€‚é»˜è®¤ä¸º 0.0ã€‚
            device (torch.device): ç”¨äºæ¨¡å‹æ¨ç†çš„è®¾å¤‡ã€‚é»˜è®¤ä¸º Noneï¼ˆcpuï¼‰ã€‚
        """
        self.t = t
        self.device = device
        self.cuda = bool(device and str(device).startswith("cuda"))

    def __enter__(self):
        """å¼€å§‹è®¡æ—¶ã€‚"""
        self.start = self.time()
        return self

    def __exit__(self, type, value, traceback):  # noqa
        """åœæ­¢è®¡æ—¶ã€‚"""
        self.dt = self.time() - self.start  # å¢é‡æ—¶é—´
        self.t += self.dt  # ç´¯åŠ å¢é‡æ—¶é—´

    def __str__(self):
        """è¿”å›è¡¨ç¤ºç´¯ç§¯ç»è¿‡æ—¶é—´çš„å¯è¯»å­—ç¬¦ä¸²ã€‚"""
        return f"Elapsed time is {self.t} s"

    def time(self):
        """è·å–å½“å‰æ—¶é—´ã€‚"""
        if self.cuda:
            torch.cuda.synchronize(self.device)
        return time.time()


def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None, padding=True, xywh=False):
    """
    å°†è¾¹ç•Œæ¡†ï¼ˆé»˜è®¤æ ¼å¼ä¸º xyxyï¼‰ä»å®ƒä»¬æœ€åˆæŒ‡å®šçš„å›¾åƒå½¢çŠ¶ï¼ˆimg1_shapeï¼‰ç¼©æ”¾åˆ°å¦ä¸€å¹…å›¾åƒçš„å½¢çŠ¶ï¼ˆimg0_shapeï¼‰ã€‚

    å‚æ•°ï¼š
        img1_shape (tuple): è¾¹ç•Œæ¡†å¯¹åº”çš„å›¾åƒçš„å½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        boxes (torch.Tensor): å›¾åƒä¸­å¯¹è±¡çš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸º (x1, y1, x2, y2)
        img0_shape (tuple): ç›®æ ‡å›¾åƒçš„å½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        ratio_pad (tuple): ä¸€ä¸ª (ratio, pad) çš„å…ƒç»„ï¼Œç”¨äºç¼©æ”¾è¾¹ç•Œæ¡†ã€‚å¦‚æœæœªæä¾›ï¼Œå°†æ ¹æ®ä¸¤ä¸ªå›¾åƒä¹‹é—´çš„å¤§å°å·®å¼‚è®¡ç®—æ¯”ç‡å’Œå¡«å……ã€‚
        padding (bool): å¦‚æœä¸º Trueï¼Œå‡è®¾è¾¹ç•Œæ¡†åŸºäº yolo é£æ ¼å¢å¼ºçš„å›¾åƒã€‚å¦‚æœä¸º Falseï¼Œåˆ™è¿›è¡Œå¸¸è§„ç¼©æ”¾ã€‚
        xywh (bool): è¾¹ç•Œæ¡†æ ¼å¼æ˜¯å¦ä¸º xywhï¼Œé»˜è®¤ä¸º Falseã€‚

    è¿”å›ï¼š
        boxes (torch.Tensor): ç¼©æ”¾åçš„è¾¹ç•Œæ¡†ï¼Œæ ¼å¼ä¸º (x1, y1, x2, y2)
    """
    if ratio_pad is None:  # ä» img0_shape è®¡ç®—
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        pad = (
            round((img1_shape[1] - img0_shape[1] * gain) / 2 - 0.1),
            round((img1_shape[0] - img0_shape[0] * gain) / 2 - 0.1),
        )  # wh å¡«å……
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    if padding:
        boxes[..., 0] -= pad[0]  # x å¡«å……
        boxes[..., 1] -= pad[1]  # y å¡«å……
        if not xywh:
            boxes[..., 2] -= pad[0]  # x å¡«å……
            boxes[..., 3] -= pad[1]  # y å¡«å……
    boxes[..., :4] /= gain
    return clip_boxes(boxes, img0_shape)


def make_divisible(x, divisor):
    """
    è¿”å›æœ€æ¥è¿‘çš„å¯è¢«ç»™å®šé™¤æ•°æ•´é™¤çš„æ•°å­—ã€‚

    å‚æ•°ï¼š
        x (int): è¦æ•´é™¤çš„æ•°å­—ã€‚
        divisor (int | torch.Tensor): é™¤æ•°ã€‚

    è¿”å›ï¼š
        (int): æœ€è¿‘çš„å¯è¢«é™¤æ•°æ•´é™¤çš„æ•°å­—ã€‚
    """
    if isinstance(divisor, torch.Tensor):
        divisor = int(divisor.max())  # è½¬ä¸º int
    return math.ceil(x / divisor) * divisor


def nms_rotated(boxes, scores, threshold=0.45):
    """
    ä½¿ç”¨ probiou å’Œ fast-nms å¯¹æ—‹è½¬è¾¹ç•Œæ¡†è¿›è¡Œ NMSã€‚

    å‚æ•°ï¼š
        boxes (torch.Tensor): æ—‹è½¬è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º (N, 5)ï¼Œæ ¼å¼ä¸º xywhrã€‚
        scores (torch.Tensor): ç½®ä¿¡åˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (N,).
        threshold (float, optional): IoU é˜ˆå€¼ã€‚é»˜è®¤ä¸º 0.45ã€‚

    è¿”å›ï¼š
        (torch.Tensor): ä¿ç•™çš„æ¡†çš„ç´¢å¼•ã€‚
    """
    if len(boxes) == 0:
        return np.empty((0,), dtype=np.int8)
    sorted_idx = torch.argsort(scores, descending=True)
    boxes = boxes[sorted_idx]
    ious = batch_probiou(boxes, boxes).triu_(diagonal=1)
    pick = torch.nonzero(ious.max(dim=0)[0] < threshold).squeeze_(-1)
    return sorted_idx[pick]


def non_max_suppression(
    prediction,
    conf_thres=0.25,
    iou_thres=0.45,
    classes=None,
    agnostic=False,
    multi_label=False,
    labels=(),
    max_det=300,
    nc=0,  # ç±»åˆ«æ•°é‡ï¼ˆå¯é€‰ï¼‰
    max_time_img=0.05,
    max_nms=30000,
    max_wh=7680,
    in_place=True,
    rotated=False,
):
    """
    å¯¹ä¸€ç»„æ¡†æ‰§è¡Œéæœ€å¤§æŠ‘åˆ¶ï¼ˆNMSï¼‰ï¼Œæ”¯æŒæ©ç å’Œæ¯ä¸ªæ¡†å¤šä¸ªæ ‡ç­¾ã€‚

    å‚æ•°ï¼š
        prediction (torch.Tensor): å½¢çŠ¶ä¸º (batch_size, num_classes + 4 + num_masks, num_boxes) çš„å¼ é‡ï¼Œ
            åŒ…å«é¢„æµ‹çš„æ¡†ã€ç±»åˆ«å’Œæ©ç ã€‚å¼ é‡åº”ä¸ºæ¨¡å‹è¾“å‡ºæ ¼å¼ï¼Œä¾‹å¦‚ YOLOã€‚
        conf_thres (float): ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºè¯¥å€¼çš„æ¡†å°†è¢«è¿‡æ»¤æ‰ã€‚
            æœ‰æ•ˆå€¼åœ¨ 0.0 å’Œ 1.0 ä¹‹é—´ã€‚
        iou_thres (float): åœ¨ NMS è¿‡ç¨‹ä¸­å°†è¢«è¿‡æ»¤æ‰çš„ IoU é˜ˆå€¼ã€‚
            æœ‰æ•ˆå€¼åœ¨ 0.0 å’Œ 1.0 ä¹‹é—´ã€‚
        classes (List[int]): è¦è€ƒè™‘çš„ç±»åˆ«ç´¢å¼•åˆ—è¡¨ã€‚å¦‚æœä¸º Noneï¼Œå°†è€ƒè™‘æ‰€æœ‰ç±»åˆ«ã€‚
        agnostic (bool): å¦‚æœä¸º Trueï¼Œæ¨¡å‹å¯¹ç±»åˆ«æ•°é‡æ— å…³ï¼Œå¹¶ä¸”æ‰€æœ‰ç±»åˆ«å°†è¢«è§†ä¸ºä¸€ä¸ªã€‚
        multi_label (bool): å¦‚æœä¸º Trueï¼Œæ¯ä¸ªæ¡†å¯èƒ½æœ‰å¤šä¸ªæ ‡ç­¾ã€‚
        labels (List[List[Union[int, float, torch.Tensor]]]): ä¸€ä¸ªåˆ—è¡¨çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå†…å±‚
            åˆ—è¡¨åŒ…å«ç»™å®šå›¾åƒçš„å…ˆéªŒæ ‡ç­¾ã€‚åˆ—è¡¨åº”ä¸ºæ•°æ®åŠ è½½å™¨è¾“å‡ºæ ¼å¼ï¼Œ
            æ¯ä¸ªæ ‡ç­¾ä¸º (class_index, x1, y1, x2, y2) çš„å…ƒç»„ã€‚
        max_det (int): NMS åä¿ç•™çš„æœ€å¤§æ¡†æ•°é‡ã€‚
        nc (int, optional): æ¨¡å‹è¾“å‡ºçš„ç±»åˆ«æ•°é‡ã€‚æ­¤ä¹‹åçš„ä»»ä½•ç´¢å¼•å°†è§†ä¸ºæ©ç ã€‚
        max_time_img (float): å¤„ç†ä¸€å¼ å›¾åƒçš„æœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        max_nms (int): ä¼ é€’ç»™ torchvision.ops.nms() çš„æœ€å¤§æ¡†æ•°é‡ã€‚
        max_wh (int): åƒç´ çš„æœ€å¤§æ¡†å®½åº¦å’Œé«˜åº¦ã€‚
        in_place (bool): å¦‚æœä¸º Trueï¼Œå°†åŸè¾“å…¥é¢„æµ‹å¼ é‡å°±åœ°ä¿®æ”¹ã€‚
        rotated (bool): å¦‚æœä¼ é€’çš„æ˜¯å®šå‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰ç”¨äº NMSã€‚

    è¿”å›ï¼š
        (List[torch.Tensor]): ä¸€ä¸ªé•¿åº¦ä¸º batch_size çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º
            (num_boxes, 6 + num_masks) çš„å¼ é‡ï¼ŒåŒ…å«ä¿ç•™çš„æ¡†ï¼Œåˆ—
            (x1, y1, x2, y2, confidence, class, mask1, mask2, ...).
    """
    import torchvision  # ä¸ºäº†æ›´å¿«çš„ 'import yololite'

    # æ£€æŸ¥
    assert 0 <= conf_thres <= 1, f"æ— æ•ˆçš„ç½®ä¿¡åº¦é˜ˆå€¼ {conf_thres}ï¼Œæœ‰æ•ˆå€¼åœ¨ 0.0 å’Œ 1.0 ä¹‹é—´"
    assert 0 <= iou_thres <= 1, f"æ— æ•ˆçš„ IoU {iou_thres}ï¼Œæœ‰æ•ˆå€¼åœ¨ 0.0 å’Œ 1.0 ä¹‹é—´"
    if isinstance(prediction, (list, tuple)):  # YOLOv8 æ¨¡å‹åœ¨éªŒè¯æ¨¡å‹ä¸­ï¼Œè¾“å‡º = (inference_out, loss_out)
        prediction = prediction[0]  # ä»…é€‰æ‹©æ¨ç†è¾“å‡º
    if classes is not None:
        classes = torch.tensor(classes, device=prediction.device)

    if prediction.shape[-1] == 6:  # ç«¯åˆ°ç«¯æ¨¡å‹ (BNCï¼Œå³ 1,300,6)
        output = [pred[pred[:, 4] > conf_thres][:max_det] for pred in prediction]
        if classes is not None:
            output = [pred[(pred[:, 5:6] == classes).any(1)] for pred in output]
        return output

    bs = prediction.shape[0]  # æ‰¹å¤„ç†å¤§å° (BCNï¼Œå³ 1,84,6300)
    nc = nc or (prediction.shape[1] - 4)  # ç±»åˆ«æ•°é‡
    nm = prediction.shape[1] - nc - 4  # æ©ç æ•°é‡
    mi = 4 + nc  # æ©ç å¼€å§‹ç´¢å¼•
    xc = prediction[:, 4:mi].amax(1) > conf_thres  # å€™é€‰æ¡†

    # è®¾ç½®
    # min_wh = 2  # (åƒç´ ) æœ€å°æ¡†å®½åº¦å’Œé«˜åº¦
    time_limit = 2.0 + max_time_img * bs  # è¶…è¿‡åé€€å‡ºçš„ç§’æ•°
    multi_label &= nc > 1  # æ¯ä¸ªæ¡†å¤šä¸ªæ ‡ç­¾ï¼ˆå¢åŠ  0.5ms/imgï¼‰

    prediction = prediction.transpose(-1, -2)  # shape(1,84,6300) è½¬æ¢ä¸º shape(1,6300,84)
    if not rotated:
        if in_place:
            prediction[..., :4] = xywh2xyxy(prediction[..., :4])  # xywh è½¬ xyxy
        else:
            prediction = torch.cat((xywh2xyxy(prediction[..., :4]), prediction[..., 4:]), dim=-1)  # xywh è½¬ xyxy

    t = time.time()
    output = [torch.zeros((0, 6 + nm), device=prediction.device)] * bs
    for xi, x in enumerate(prediction):  # å›¾åƒç´¢å¼•ï¼Œå›¾åƒæ¨ç†
        # åº”ç”¨çº¦æŸ
        # x[((x[:, 2:4] < min_wh) | (x[:, 2:4] > max_wh)).any(1), 4] = 0  # å®½é«˜
        x = x[xc[xi]]  # ç½®ä¿¡åº¦

        # å¦‚æœè‡ªåŠ¨æ ‡æ³¨ï¼Œåˆ™è¿æ¥å…ˆå‰æ ‡ç­¾
        if labels and len(labels[xi]) and not rotated:
            lb = labels[xi]
            v = torch.zeros((len(lb), nc + nm + 4), device=x.device)
            v[:, :4] = xywh2xyxy(lb[:, 1:5])  # è¾¹ç•Œæ¡†
            v[range(len(lb)), lb[:, 0].long() + 4] = 1.0  # ç±»
            x = torch.cat((x, v), 0)

        # å¦‚æœæ²¡æœ‰å‰©ä½™ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªå›¾åƒ
        if not x.shape[0]:
            continue

        # æ£€æµ‹çŸ©é˜µ nx6 (xyxy, conf, cls)
        box, cls, mask = x.split((4, nc, nm), 1)

        if multi_label:
            i, j = torch.where(cls > conf_thres)
            x = torch.cat((box[i], x[i, 4 + j, None], j[:, None].float(), mask[i]), 1)
        else:  # ä»…æœ€ä½³ç±»åˆ«
            conf, j = cls.max(1, keepdim=True)
            x = torch.cat((box, conf, j.float(), mask), 1)[conf.view(-1) > conf_thres]

        # æŒ‰ç±»åˆ«ç­›é€‰
        if classes is not None:
            x = x[(x[:, 5:6] == classes).any(1)]

        # æ£€æŸ¥å½¢çŠ¶
        n = x.shape[0]  # æ¡†æ•°é‡
        if not n:  # æ²¡æœ‰æ¡†
            continue
        if n > max_nms:  # è¶…è¿‡æ¡†æ•°é‡
            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # æŒ‰ç½®ä¿¡åº¦æ’åºå¹¶ç§»é™¤å¤šä½™æ¡†

        # æ‰¹é‡ NMS
        c = x[:, 5:6] * (0 if agnostic else max_wh)  # ç±»åˆ«
        scores = x[:, 4]  # åˆ†æ•°
        if rotated:
            boxes = torch.cat((x[:, :2] + c, x[:, 2:4], x[:, -1:]), dim=-1)  # xywhr
            i = nms_rotated(boxes, scores, iou_thres)
        else:
            boxes = x[:, :4] + c  # æ¡†ï¼ˆæŒ‰ç±»åˆ«åç§»ï¼‰
            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
        i = i[:max_det]  # é™åˆ¶æ£€æµ‹æ•°é‡

        output[xi] = x[i]
        if (time.time() - t) > time_limit:
            LOGGER.warning(f"WARNING âš ï¸ NMS è¶…è¿‡æ—¶é—´é™åˆ¶ {time_limit:.3f}s")
            break  # è¶…è¿‡æ—¶é—´é™åˆ¶

    return output


def clip_boxes(boxes, shape):
    """
    è·å–è¾¹ç•Œæ¡†åˆ—è¡¨å’Œå½¢çŠ¶ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ï¼Œå¹¶å°†è¾¹ç•Œæ¡†å‰ªè£åˆ°è¯¥å½¢çŠ¶ã€‚

    å‚æ•°ï¼š
        boxes (torch.Tensor): è¦å‰ªè£çš„è¾¹ç•Œæ¡†
        shape (tuple): å›¾åƒçš„å½¢çŠ¶

    è¿”å›ï¼š
        (torch.Tensor | numpy.ndarray): å‰ªè£åçš„æ¡†
    """
    if isinstance(boxes, torch.Tensor):  # æ›´å¿«çš„å•ç‹¬å¤„ç†ï¼ˆè­¦å‘Šï¼šå°±åœ° .clamp_() çš„ Apple MPS bugï¼‰
        boxes[..., 0] = boxes[..., 0].clamp(0, shape[1])  # x1
        boxes[..., 1] = boxes[..., 1].clamp(0, shape[0])  # y1
        boxes[..., 2] = boxes[..., 2].clamp(0, shape[1])  # x2
        boxes[..., 3] = boxes[..., 3].clamp(0, shape[0])  # y2
    else:  # np.arrayï¼ˆæ›´å¿«çš„æ‰¹é‡å¤„ç†ï¼‰
        boxes[..., [0, 2]] = boxes[..., [0, 2]].clip(0, shape[1])  # x1, x2
        boxes[..., [1, 3]] = boxes[..., [1, 3]].clip(0, shape[0])  # y1, y2
    return boxes


def clip_coords(coords, shape):
    """
    å°†çº¿åæ ‡å‰ªè£åˆ°å›¾åƒè¾¹ç•Œã€‚

    å‚æ•°ï¼š
        coords (torch.Tensor | numpy.ndarray): ä¸€ç»„çº¿åæ ‡ã€‚
        shape (tuple): ä»£è¡¨å›¾åƒå¤§å°çš„æ•´æ•°å…ƒç»„ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚

    è¿”å›ï¼š
        (torch.Tensor | numpy.ndarray): å‰ªè£åçš„åæ ‡
    """
    if isinstance(coords, torch.Tensor):  # æ›´å¿«çš„å•ç‹¬å¤„ç†ï¼ˆè­¦å‘Šï¼šå°±åœ° .clamp_() çš„ Apple MPS bugï¼‰
        coords[..., 0] = coords[..., 0].clamp(0, shape[1])  # x
        coords[..., 1] = coords[..., 1].clamp(0, shape[0])  # y
    else:  # np.arrayï¼ˆæ›´å¿«çš„æ‰¹é‡å¤„ç†ï¼‰
        coords[..., 0] = coords[..., 0].clip(0, shape[1])  # x
        coords[..., 1] = coords[..., 1].clip(0, shape[0])  # y
    return coords


def scale_image(masks, im0_shape, ratio_pad=None):
    """
    è·å–ä¸€ä¸ªæ©ç ï¼Œå¹¶å°†å…¶è°ƒæ•´ä¸ºåŸå§‹å›¾åƒå¤§å°ã€‚

    å‚æ•°ï¼š
        masks (np.ndarray): è°ƒæ•´å¤§å°å’Œå¡«å……çš„æ©ç /å›¾åƒï¼Œå½¢çŠ¶ä¸º [h, w, num]/[h, w, 3]ã€‚
        im0_shape (tuple): åŸå§‹å›¾åƒçš„å½¢çŠ¶
        ratio_pad (tuple): ç”¨äºåŸå§‹å›¾åƒçš„å¡«å……æ¯”ç‡ã€‚

    è¿”å›ï¼š
        masks (np.ndarray): å½¢çŠ¶ä¸º [h, w, num] çš„æ©ç ã€‚
    """
    # ä» im1_shape ç¼©æ”¾åæ ‡ (xyxy) åˆ° im0_shape
    im1_shape = masks.shape
    if im1_shape[:2] == im0_shape[:2]:
        return masks
    if ratio_pad is None:  # ä» im0_shape è®¡ç®—
        gain = min(im1_shape[0] / im0_shape[0], im1_shape[1] / im0_shape[1])  # gain  = old / new
        pad = (im1_shape[1] - im0_shape[1] * gain) / 2, (im1_shape[0] - im0_shape[0] * gain) / 2  # wh å¡«å……
    else:
        pad = ratio_pad[1]
    top, left = int(pad[1]), int(pad[0])  # y, x
    bottom, right = int(im1_shape[0] - pad[1]), int(im1_shape[1] - pad[0])

    if len(masks.shape) < 2:
        raise ValueError(f'"len of masks shape" åº”ä¸º 2 æˆ– 3ï¼Œä½†å¾—åˆ° {len(masks.shape)}')
    masks = masks[top:bottom, left:right]
    masks = cv2.resize(masks, (im0_shape[1], im0_shape[0]))
    if len(masks.shape) == 2:
        masks = masks[:, :, None]

    return masks


def xyxy2xywh(x):
    """
    å°†è¾¹ç•Œæ¡†åæ ‡ä» (x1, y1, x2, y2) æ ¼å¼è½¬æ¢ä¸º (x, y, width, height) æ ¼å¼ï¼Œå…¶ä¸­ (x1, y1) æ˜¯
    å·¦ä¸Šè§’ï¼Œ(x2, y2) æ˜¯å³ä¸‹è§’ã€‚

    å‚æ•°ï¼š
        x (np.ndarray | torch.Tensor): è¾“å…¥çš„è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º (x1, y1, x2, y2)ã€‚

    è¿”å›ï¼š
        y (np.ndarray | torch.Tensor): è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º (x, y, width, height)ã€‚
    """
    assert x.shape[-1] == 4, f"è¾“å…¥å½¢çŠ¶æœ€åç»´åº¦æœŸæœ›ä¸º 4ï¼Œä½†è¾“å…¥å½¢çŠ¶ä¸º {x.shape}"
    y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)  # æ¯”å…‹éš†/å¤åˆ¶æ›´å¿«
    y[..., 0] = (x[..., 0] + x[..., 2]) / 2  # x ä¸­å¿ƒ
    y[..., 1] = (x[..., 1] + x[..., 3]) / 2  # y ä¸­å¿ƒ
    y[..., 2] = x[..., 2] - x[..., 0]  # å®½åº¦
    y[..., 3] = x[..., 3] - x[..., 1]  # é«˜åº¦
    return y


def xywh2xyxy(x):
    """
    å°†è¾¹ç•Œæ¡†åæ ‡ä» (x, y, width, height) æ ¼å¼è½¬æ¢ä¸º (x1, y1, x2, y2) æ ¼å¼ï¼Œå…¶ä¸­ (x1, y1) æ˜¯
    å·¦ä¸Šè§’ï¼Œ(x2, y2) æ˜¯å³ä¸‹è§’ã€‚æ³¨æ„ï¼šæ¯ 2 ä¸ªé€šé“çš„æ“ä½œæ¯”æ¯ä¸ªé€šé“çš„æ“ä½œæ›´å¿«ã€‚

    å‚æ•°ï¼š
        x (np.ndarray | torch.Tensor): è¾“å…¥çš„è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º (x, y, width, height)ã€‚

    è¿”å›ï¼š
        y (np.ndarray | torch.Tensor): è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º (x1, y1, x2, y2)ã€‚
    """
    assert x.shape[-1] == 4, f"è¾“å…¥å½¢çŠ¶æœ€åç»´åº¦æœŸæœ›ä¸º 4ï¼Œä½†è¾“å…¥å½¢çŠ¶ä¸º {x.shape}"
    y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)  # æ¯”å…‹éš†/å¤åˆ¶æ›´å¿«
    xy = x[..., :2]  # ä¸­å¿ƒ
    wh = x[..., 2:] / 2  # åŠå®½é«˜
    y[..., :2] = xy - wh  # å·¦ä¸Šè§’ xy
    y[..., 2:] = xy + wh  # å³ä¸‹è§’ xy
    return y


def xywh2ltwh(x):
    """
    å°†è¾¹ç•Œæ¡†æ ¼å¼ä» [x, y, w, h] è½¬æ¢ä¸º [x1, y1, w, h]ï¼Œå…¶ä¸­ x1, y1 æ˜¯å·¦ä¸Šè§’åæ ‡ã€‚

    å‚æ•°ï¼š
        x (np.ndarray | torch.Tensor): è¾“å…¥å¼ é‡ï¼ŒåŒ…å«è¾¹ç•Œæ¡†åæ ‡ã€‚

    è¿”å›ï¼š
        y (np.ndarray | torch.Tensor): è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º xyltwhã€‚
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[..., 0] = x[..., 0] - x[..., 2] / 2  # å·¦ä¸Šè§’ x
    y[..., 1] = x[..., 1] - x[..., 3] / 2  # å·¦ä¸Šè§’ y
    return y


def xyxy2ltwh(x):
    """
    å°† nx4 è¾¹ç•Œæ¡†ä» [x1, y1, x2, y2] è½¬æ¢ä¸º [x1, y1, w, h]ï¼Œå…¶ä¸­ xy1=å·¦ä¸Šè§’ï¼Œxy2=å³ä¸‹è§’ã€‚

    å‚æ•°ï¼š
        x (np.ndarray | torch.Tensor): è¾“å…¥å¼ é‡ï¼ŒåŒ…å«è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º xyxyã€‚

    è¿”å›ï¼š
        y (np.ndarray | torch.Tensor): è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º xyltwhã€‚
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[..., 2] = x[..., 2] - x[..., 0]  # å®½åº¦
    y[..., 3] = x[..., 3] - x[..., 1]  # é«˜åº¦
    return y


def ltwh2xywh(x):
    """
    å°† nx4 æ¡†ä» [x1, y1, w, h] è½¬æ¢ä¸º [x, y, w, h]ï¼Œå…¶ä¸­ xy1=å·¦ä¸Šè§’ï¼Œxy=centerã€‚

    å‚æ•°ï¼š
        x (torch.Tensor): è¾“å…¥å¼ é‡ã€‚

    è¿”å›ï¼š
        y (np.ndarray | torch.Tensor): è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º xywhã€‚
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[..., 0] = x[..., 0] + x[..., 2] / 2  # ä¸­å¿ƒ x
    y[..., 1] = x[..., 1] + x[..., 3] / 2  # ä¸­å¿ƒ y
    return y


def xywhr2xyxyxyxy(x):
    """
    å°†æ‰¹é‡å®šå‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰ä» [xywh, æ—‹è½¬] è½¬æ¢ä¸º [xy1, xy2, xy3, xy4]ã€‚æ—‹è½¬å€¼åº”ä¸º
    ä» 0 åˆ° pi/2 çš„å¼§åº¦ã€‚

    å‚æ•°ï¼š
        x (numpy.ndarray | torch.Tensor): å½¢çŠ¶ä¸º (n, 5) æˆ– (b, n, 5) çš„æ¡†ï¼Œæ ¼å¼ä¸º [cx, cy, w, h, æ—‹è½¬]ã€‚

    è¿”å›ï¼š
        (numpy.ndarray | torch.Tensor): è½¬æ¢åçš„è§’ç‚¹ï¼Œå½¢çŠ¶ä¸º (n, 4, 2) æˆ– (b, n, 4, 2)ã€‚
    """
    cos, sin, cat, stack = (
        (torch.cos, torch.sin, torch.cat, torch.stack)
        if isinstance(x, torch.Tensor)
        else (np.cos, np.sin, np.concatenate, np.stack)
    )

    ctr = x[..., :2]
    w, h, angle = (x[..., i : i + 1] for i in range(2, 5))
    cos_value, sin_value = cos(angle), sin(angle)
    vec1 = [w / 2 * cos_value, w / 2 * sin_value]
    vec2 = [-h / 2 * sin_value, h / 2 * cos_value]
    vec1 = cat(vec1, -1)
    vec2 = cat(vec2, -1)
    pt1 = ctr + vec1 + vec2
    pt2 = ctr + vec1 - vec2
    pt3 = ctr - vec1 - vec2
    pt4 = ctr - vec1 + vec2
    return stack([pt1, pt2, pt3, pt4], -2)


def ltwh2xyxy(x):
    """
    å°†è¾¹ç•Œæ¡†ä» [x1, y1, w, h] è½¬æ¢ä¸º [x1, y1, x2, y2]ï¼Œå…¶ä¸­ xy1=å·¦ä¸Šè§’ï¼Œxy2=å³ä¸‹è§’ã€‚

    å‚æ•°ï¼š
        x (np.ndarray | torch.Tensor): è¾“å…¥å›¾åƒ

    è¿”å›ï¼š
        y (np.ndarray | torch.Tensor): è¾¹ç•Œæ¡†çš„ xyxy åæ ‡ã€‚
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[..., 2] = x[..., 2] + x[..., 0]  # å®½åº¦
    y[..., 3] = x[..., 3] + x[..., 1]  # é«˜åº¦
    return y


def convert_torch2numpy_batch(batch: torch.Tensor) -> np.ndarray:
    return (batch.permute(0, 2, 3, 1).contiguous() * 255).clamp(0, 255).to(torch.uint8).cpu().numpy()


def clean_str(s):
    return re.sub(pattern="[|@#!Â¡Â·$â‚¬%&()=?Â¿^*;:,Â¨Â´><+]", repl="_", string=s)