# YOLO-Lite ğŸš€

import contextlib
import pickle
import re
import types
from copy import deepcopy
from pathlib import Path

import torch
import torch.nn as nn

from yololite.nn.modules import (
    AIFI,
    C1,
    C2,
    C2PSA,
    C3,
    C3TR,
    ELAN1,
    PSA,
    SPP,
    SPPELAN,
    SPPF,
    AConv,
    ADown,
    Bottleneck,
    BottleneckCSP,
    C2f,
    C2fAttn,
    C2fCIB,
    C2fPSA,
    C3Ghost,
    C3k2,
    C3x,
    CBFuse,
    CBLinear,
    Concat,
    Conv,
    Conv2,
    ConvTranspose,
    Detect,
    DWConv,
    DWConvTranspose2d,
    Focus,
    GhostBottleneck,
    GhostConv,
    HGBlock,
    HGStem,
    ImagePoolingAttn,
    RepC3,
    RepNCSPELAN4,
    ResNetLayer,
    SCDown,
)
from yololite.utils import DEFAULT_CFG_DICT, DEFAULT_CFG_KEYS, LOGGER, colorstr, yaml_load
from yololite.utils.checks import check_requirements
from yololite.utils.loss import (
    E2EDetectLoss,
    v8DetectionLoss,
)
from yololite.utils.ops import make_divisible
from yololite.utils.plotting import feature_visualization
from yololite.utils.torch_utils import (
    fuse_conv_and_bn,
    fuse_deconv_and_bn,
    initialize_weights,
    intersect_dicts,
    scale_img,
    time_sync,
)

try:
    import thop
except ImportError:
    thop = None


class BaseModel(nn.Module):
    """BaseModel ç±»ä½œä¸º YOLO-Lite ä¸­æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ã€‚"""

    def forward(self, x, *args, **kwargs):
        """
        æ‰§è¡Œæ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œç”¨äºè®­ç»ƒæˆ–æ¨ç†ã€‚

        å¦‚æœ x æ˜¯å­—å…¸ï¼Œåˆ™è®¡ç®—å¹¶è¿”å›è®­ç»ƒçš„æŸå¤±ã€‚å¦åˆ™ï¼Œè¿”å›æ¨ç†çš„é¢„æµ‹ç»“æœã€‚

        å‚æ•°ï¼š
            x (torch.Tensor | dict): ç”¨äºæ¨ç†çš„è¾“å…¥å¼ é‡ï¼Œæˆ–å¸¦æœ‰å›¾åƒå¼ é‡å’Œæ ‡ç­¾çš„å­—å…¸ç”¨äºè®­ç»ƒã€‚
            *args (Any): å¯å˜é•¿åº¦çš„å‚æ•°åˆ—è¡¨ã€‚
            **kwargs (Any): ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        è¿”å›ï¼š
            (torch.Tensor): å¦‚æœ x æ˜¯å­—å…¸ï¼ˆè®­ç»ƒï¼‰ï¼Œåˆ™è¿”å›æŸå¤±ï¼›å¦åˆ™è¿”å›ç½‘ç»œé¢„æµ‹ï¼ˆæ¨ç†ï¼‰ã€‚
        """
        if isinstance(x, dict):  # è®­ç»ƒå’ŒéªŒè¯æ—¶çš„æƒ…å†µã€‚
            return self.loss(x, *args, **kwargs)
        return self.predict(x, *args, **kwargs)

    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):
        """
        é€šè¿‡ç½‘ç»œæ‰§è¡Œå‰å‘ä¼ æ’­ã€‚

        å‚æ•°ï¼š
            x (torch.Tensor): æ¨¡å‹çš„è¾“å…¥å¼ é‡ã€‚
            profile (bool): å¦‚æœä¸º Trueï¼Œæ‰“å°æ¯å±‚çš„è®¡ç®—æ—¶é—´ï¼Œé»˜è®¤ä¸º Falseã€‚
            visualize (bool): å¦‚æœä¸º Trueï¼Œä¿å­˜æ¨¡å‹çš„ç‰¹å¾å›¾ï¼Œé»˜è®¤ä¸º Falseã€‚
            augment (bool): åœ¨é¢„æµ‹æ—¶å¢å¼ºå›¾åƒï¼Œé»˜è®¤ä¸º Falseã€‚
            embed (list, optional): è¦è¿”å›çš„ç‰¹å¾å‘é‡/åµŒå…¥çš„åˆ—è¡¨ã€‚

        è¿”å›ï¼š
            (torch.Tensor): æ¨¡å‹çš„æœ€åè¾“å‡ºã€‚
        """
        if augment:
            return self._predict_augment(x)
        return self._predict_once(x, profile, visualize, embed)

    def _predict_once(self, x, profile=False, visualize=False, embed=None):
        """
        é€šè¿‡ç½‘ç»œæ‰§è¡Œå‰å‘ä¼ æ’­ã€‚

        å‚æ•°ï¼š
            x (torch.Tensor): æ¨¡å‹çš„è¾“å…¥å¼ é‡ã€‚
            profile (bool): å¦‚æœä¸º Trueï¼Œæ‰“å°æ¯å±‚çš„è®¡ç®—æ—¶é—´ï¼Œé»˜è®¤ä¸º Falseã€‚
            visualize (bool): å¦‚æœä¸º Trueï¼Œä¿å­˜æ¨¡å‹çš„ç‰¹å¾å›¾ï¼Œé»˜è®¤ä¸º Falseã€‚
            embed (list, optional): è¦è¿”å›çš„ç‰¹å¾å‘é‡/åµŒå…¥çš„åˆ—è¡¨ã€‚

        è¿”å›ï¼š
            (torch.Tensor): æ¨¡å‹çš„æœ€åè¾“å‡ºã€‚
        """
        y, dt, embeddings = [], [], []  # è¾“å‡º
        for m in self.model:
            if m.f != -1:  # å¦‚æœä¸æ˜¯æ¥è‡ªå‰ä¸€å±‚
                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # æ¥è‡ªæ—©æœŸå±‚
            if profile:
                self._profile_one_layer(m, x, dt)
            x = m(x)  # è¿è¡Œ
            y.append(x if m.i in self.save else None)  # ä¿å­˜è¾“å‡º
            if visualize:
                feature_visualization(x, m.type, m.i, save_dir=visualize)
            if embed and m.i in embed:
                embeddings.append(nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1))  # æ‹‰å¹³
                if m.i == max(embed):
                    return torch.unbind(torch.cat(embeddings, 1), dim=0)
        return x

    def _predict_augment(self, x):
        """å¯¹è¾“å…¥å›¾åƒ x æ‰§è¡Œå¢å¼ºå¹¶è¿”å›å¢å¼ºçš„æ¨ç†ã€‚"""
        LOGGER.warning(
            f"WARNING âš ï¸ {self.__class__.__name__} ä¸æ”¯æŒ 'augment=True' é¢„æµ‹ã€‚"
            f"å›é€€åˆ°å•å°ºåº¦é¢„æµ‹ã€‚"
        )
        return self._predict_once(x)

    def _profile_one_layer(self, m, x, dt):
        """
        å¯¹æ¨¡å‹å•å±‚çš„è®¡ç®—æ—¶é—´å’Œ FLOPs è¿›è¡Œåˆ†æã€‚ç»“æœé™„åŠ åˆ°æä¾›çš„åˆ—è¡¨ä¸­ã€‚

        å‚æ•°ï¼š
            m (nn.Module): è¦åˆ†æçš„å±‚ã€‚
            x (torch.Tensor): è¾“å…¥æ•°æ®åˆ°è¯¥å±‚ã€‚
            dt (list): ç”¨äºå­˜å‚¨è¯¥å±‚è®¡ç®—æ—¶é—´çš„åˆ—è¡¨ã€‚

        è¿”å›ï¼š
            None
        """
        c = m == self.model[-1] and isinstance(x, list)  # æ˜¯å¦ä¸ºæœ€ç»ˆå±‚åˆ—è¡¨ï¼Œå¤åˆ¶è¾“å…¥ä»¥ä¿®å¤å°±åœ°é—®é¢˜
        flops = thop.profile(m, inputs=[x.copy() if c else x], verbose=False)[0] / 1e9 * 2 if thop else 0  # GFLOPs
        t = time_sync()
        for _ in range(10):
            m(x.copy() if c else x)
        dt.append((time_sync() - t) * 100)
        if m == self.model[0]:
            LOGGER.info(f"{'time (ms)':>10s} {'GFLOPs':>10s} {'params':>10s}  module")
        LOGGER.info(f"{dt[-1]:10.2f} {flops:10.2f} {m.np:10.0f}  {m.type}")
        if c:
            LOGGER.info(f"{sum(dt):10.2f} {'-':>10s} {'-':>10s}  Total")

    def _apply(self, fn):
        """
        å°†å‡½æ•°åº”ç”¨äºæ¨¡å‹ä¸­æ‰€æœ‰ä¸æ˜¯å‚æ•°æˆ–æ³¨å†Œç¼“å†²åŒºçš„å¼ é‡ã€‚

        å‚æ•°ï¼š
            fn (function): è¦åº”ç”¨äºæ¨¡å‹çš„å‡½æ•°

        è¿”å›ï¼š
            (BaseModel): æ›´æ–°åçš„ BaseModel å¯¹è±¡ã€‚
        """
        self = super()._apply(fn)
        m = self.model[-1]  # Detect()
        if isinstance(m, Detect):  # åŒ…æ‹¬æ‰€æœ‰ Detect å­ç±»ï¼Œå¦‚ Segmentã€Poseã€OBBã€WorldDetect
            m.stride = fn(m.stride)
            m.anchors = fn(m.anchors)
            m.strides = fn(m.strides)
        return self

    def load(self, weights, verbose=True):
        """
        å°†æƒé‡åŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚

        å‚æ•°ï¼š
            weights (dict | torch.nn.Module): è¦åŠ è½½çš„é¢„è®­ç»ƒæƒé‡ã€‚
            verbose (bool, optional): æ˜¯å¦è®°å½•è½¬ç§»è¿›åº¦ã€‚é»˜è®¤ä¸º Trueã€‚
        """
        model = weights["model"] if isinstance(weights, dict) else weights  # torchvision æ¨¡å‹ä¸æ˜¯å­—å…¸
        csd = model.float().state_dict()  # æ£€æŸ¥ç‚¹çŠ¶æ€å­—å…¸ä¸º FP32
        csd = intersect_dicts(csd, self.state_dict())  # äº¤é›†
        self.load_state_dict(csd, strict=False)  # åŠ è½½
        if verbose:
            LOGGER.info(f"Transferred {len(csd)}/{len(self.model.state_dict())} items from pretrained weights")

    def loss(self, batch, preds=None):
        """
        è®¡ç®—æŸå¤±ã€‚

        å‚æ•°ï¼š
            batch (dict): è®¡ç®—æŸå¤±çš„æ‰¹æ¬¡
            preds (torch.Tensor | List[torch.Tensor]): é¢„æµ‹ç»“æœã€‚
        """
        if getattr(self, "criterion", None) is None:
            self.criterion = self.init_criterion()

        preds = self.forward(batch["img"]) if preds is None else preds
        return self.criterion(preds, batch)

    def init_criterion(self):
        """åˆå§‹åŒ– BaseModel çš„æŸå¤±æ ‡å‡†ã€‚"""
        raise NotImplementedError("compute_loss() éœ€è¦ç”±ä»»åŠ¡å¤´å®ç°")


class DetectionModel(BaseModel):
    """YOLOv8 æ£€æµ‹æ¨¡å‹ã€‚"""

    def __init__(self, cfg="yolov8n.yaml", ch=3, nc=None, verbose=True):  # æ¨¡å‹ï¼Œè¾“å…¥é€šé“ï¼Œç±»åˆ«æ•°é‡
        """ä½¿ç”¨ç»™å®šçš„é…ç½®å’Œå‚æ•°åˆå§‹åŒ– YOLOv8 æ£€æµ‹æ¨¡å‹ã€‚"""
        super().__init__()
        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)  # é…ç½®å­—å…¸
        if self.yaml["backbone"][0][2] == "Silence":
            LOGGER.warning(
                "WARNING âš ï¸ YOLOv9 `Silence` æ¨¡å—å·²å¼ƒç”¨ï¼Œæ›¿æ¢ä¸º nn.Identityã€‚"
                "è¯·åˆ é™¤æœ¬åœ° *.pt æ–‡ä»¶å¹¶é‡æ–°ä¸‹è½½æœ€æ–°æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚"
            )
            self.yaml["backbone"][0][2] = "nn.Identity"

        # å®šä¹‰æ¨¡å‹
        ch = self.yaml["ch"] = self.yaml.get("ch", ch)  # è¾“å…¥é€šé“
        if nc and nc != self.yaml["nc"]:
            LOGGER.info(f"è¦†ç›– model.yaml nc={self.yaml['nc']} ä¸º nc={nc}")
            self.yaml["nc"] = nc  # è¦†ç›– YAML å€¼
        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)  # æ¨¡å‹ï¼Œä¿å­˜åˆ—è¡¨
        self.names = {i: f"{i}" for i in range(self.yaml["nc"])}  # é»˜è®¤åç§°å­—å…¸
        self.inplace = self.yaml.get("inplace", True)
        self.end2end = getattr(self.model[-1], "end2end", False)

        # æ„å»ºæ­¥å¹…
        m = self.model[-1]  # Detect()
        if isinstance(m, Detect):  # åŒ…æ‹¬æ‰€æœ‰ Detect å­ç±»ï¼Œå¦‚ Segmentã€Poseã€OBBã€WorldDetect
            s = 256  # 2x æœ€å°æ­¥å¹…
            m.inplace = self.inplace

            def _forward(x):
                """æ‰§è¡Œé€šè¿‡æ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œå¤„ç†ä¸åŒ Detect å­ç±»ç±»å‹ã€‚"""
                if self.end2end:
                    return self.forward(x)["one2many"]
                return self.forward(x)

            m.stride = torch.tensor([s / x.shape[-2] for x in _forward(torch.zeros(1, ch, s, s))])  # å‰å‘ä¼ æ’­
            self.stride = m.stride
            m.bias_init()  # ä»…è¿è¡Œä¸€æ¬¡
        else:
            self.stride = torch.Tensor([32])  # é»˜è®¤æ­¥å¹…ï¼Œå³ RTDETR

        # åˆå§‹åŒ–æƒé‡ï¼Œåç½®
        initialize_weights(self)
        if verbose:
            LOGGER.info("")

    def _predict_augment(self, x):
        """å¯¹è¾“å…¥å›¾åƒ x æ‰§è¡Œå¢å¼ºå¹¶è¿”å›å¢å¼ºçš„æ¨ç†å’Œè®­ç»ƒè¾“å‡ºã€‚"""
        if getattr(self, "end2end", False) or self.__class__.__name__ != "DetectionModel":
            LOGGER.warning("WARNING âš ï¸ æ¨¡å‹ä¸æ”¯æŒ 'augment=True'ï¼Œå›é€€åˆ°å•å°ºåº¦é¢„æµ‹ã€‚")
            return self._predict_once(x)
        img_size = x.shape[-2:]  # é«˜åº¦ï¼Œå®½åº¦
        s = [1, 0.83, 0.67]  # ç¼©æ”¾
        f = [None, 3, None]  # ç¿»è½¬ï¼ˆ2-ä¸Šä¸‹ç¿»è½¬ï¼Œ3-å·¦å³ç¿»è½¬ï¼‰
        y = []  # è¾“å‡º
        for si, fi in zip(s, f):
            xi = scale_img(x.flip(fi) if fi else x, si, gs=int(self.stride.max()))
            yi = super().predict(xi)[0]  # å‰å‘ä¼ æ’­
            yi = self._descale_pred(yi, fi, si, img_size)
            y.append(yi)
        y = self._clip_augmented(y)  # è£å‰ªå¢å¼ºçš„å°¾éƒ¨
        return torch.cat(y, -1), None  # å¢å¼ºçš„æ¨ç†ï¼Œè®­ç»ƒ

    @staticmethod
    def _descale_pred(p, flips, scale, img_size, dim=1):
        """å¯¹å¢å¼ºæ¨ç†åçš„é¢„æµ‹è¿›è¡Œåç¼©æ”¾ï¼ˆé€†æ“ä½œï¼‰ã€‚"""
        p[:, :4] /= scale  # åç¼©æ”¾
        x, y, wh, cls = p.split((1, 1, 2, p.shape[dim] - 4), dim)
        if flips == 2:
            y = img_size[0] - y  # åç¿»è½¬ä¸Šä¸‹
        elif flips == 3:
            x = img_size[1] - x  # åç¿»è½¬å·¦å³
        return torch.cat((x, y, wh, cls), dim)

    def _clip_augmented(self, y):
        """è£å‰ª YOLO å¢å¼ºæ¨ç†çš„å°¾éƒ¨ã€‚"""
        nl = self.model[-1].nl  # æ£€æµ‹å±‚æ•°é‡ (P3-P5)
        g = sum(4**x for x in range(nl))  # ç½‘æ ¼ç‚¹
        e = 1  # æ’é™¤å±‚è®¡æ•°
        i = (y[0].shape[-1] // g) * sum(4**x for x in range(e))  # ç´¢å¼•
        y[0] = y[0][..., :-i]  # å¤§
        i = (y[-1].shape[-1] // g) * sum(4 ** (nl - 1 - x) for x in range(e))  # ç´¢å¼•
        y[-1] = y[-1][..., i:]  # å°
        return y

    def init_criterion(self):
        """åˆå§‹åŒ– DetectionModel çš„æŸå¤±æ ‡å‡†ã€‚"""
        return E2EDetectLoss(self) if getattr(self, "end2end", False) else v8DetectionLoss(self)


# å‡½æ•° ------------------------------------------------------------------------------------------------------------


@contextlib.contextmanager
def temporary_modules(modules=None, attributes=None):
    """
    ç”¨äºæš‚æ—¶æ·»åŠ æˆ–ä¿®æ”¹ Python æ¨¡å—ç¼“å­˜ï¼ˆ`sys.modules`ï¼‰ä¸­çš„æ¨¡å—çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚

    æ­¤å‡½æ•°å¯ç”¨äºåœ¨è¿è¡Œæ—¶æ›´æ”¹æ¨¡å—è·¯å¾„ã€‚å½“é‡æ„ä»£ç æ—¶ï¼Œ
    å¦‚æœå°†æ¨¡å—ä»ä¸€ä¸ªä½ç½®ç§»åŠ¨åˆ°å¦ä¸€ä¸ªä½ç½®ï¼Œä½†ä»å¸Œæœ›æ”¯æŒæ—§çš„å¯¼å…¥è·¯å¾„ä»¥ä¿æŒå‘åå…¼å®¹æ€§ï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚

    å‚æ•°ï¼š
        modules (dict, optional): ä¸€ä¸ªå­—å…¸ï¼Œå°†æ—§æ¨¡å—è·¯å¾„æ˜ å°„åˆ°æ–°æ¨¡å—è·¯å¾„ã€‚
        attributes (dict, optional): ä¸€ä¸ªå­—å…¸ï¼Œå°†æ—§æ¨¡å—å±æ€§æ˜ å°„åˆ°æ–°æ¨¡å—å±æ€§ã€‚

    ç¤ºä¾‹ï¼š
        ```python
        with temporary_modules({"old.module": "new.module"}, {"old.module.attribute": "new.module.attribute"}):
            import old.module  # è¿™å°†å¯¼å…¥ new.module
            from old.module import attribute  # è¿™å°†å¯¼å…¥ new.module.attribute
        ```

    æ³¨æ„ï¼š
        æ›´æ”¹ä»…åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å†…éƒ¨ç”Ÿæ•ˆï¼Œé€€å‡ºä¸Šä¸‹æ–‡ç®¡ç†å™¨åå°†è¢«æ’¤é”€ã€‚
        ç›´æ¥æ“ä½œ `sys.modules` å¯èƒ½ä¼šå¯¼è‡´ä¸å¯é¢„æµ‹çš„ç»“æœï¼Œç‰¹åˆ«æ˜¯åœ¨è¾ƒå¤§çš„åº”ç”¨ç¨‹åºæˆ–åº“ä¸­ã€‚è¯·è°¨æ…ä½¿ç”¨æ­¤å‡½æ•°ã€‚
    """
    if modules is None:
        modules = {}
    if attributes is None:
        attributes = {}
    import sys
    from importlib import import_module

    try:
        # åœ¨æ—§åç§°ä¸‹è®¾ç½® sys.modules ä¸­çš„å±æ€§
        for old, new in attributes.items():
            old_module, old_attr = old.rsplit(".", 1)
            new_module, new_attr = new.rsplit(".", 1)
            setattr(import_module(old_module), old_attr, getattr(import_module(new_module), new_attr))

        # åœ¨æ—§åç§°ä¸‹è®¾ç½® sys.modules ä¸­çš„æ¨¡å—
        for old, new in modules.items():
            sys.modules[old] = import_module(new)

        yield
    finally:
        # åˆ é™¤ä¸´æ—¶æ¨¡å—è·¯å¾„
        for old in modules:
            if old in sys.modules:
                del sys.modules[old]


class SafeClass:
    """åœ¨ååºåˆ—åŒ–æœŸé—´æ›¿æ¢æœªçŸ¥ç±»çš„å ä½ç¬¦ç±»ã€‚"""

    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ– SafeClass å®ä¾‹ï¼Œå¿½ç•¥æ‰€æœ‰å‚æ•°ã€‚"""
        pass

    def __call__(self, *args, **kwargs):
        """è¿è¡Œ SafeClass å®ä¾‹ï¼Œå¿½ç•¥æ‰€æœ‰å‚æ•°ã€‚"""
        pass


class SafeUnpickler(pickle.Unpickler):
    """è‡ªå®šä¹‰ Unpicklerï¼Œç”¨äºåœ¨æœªçŸ¥ç±»æ—¶å°†å…¶æ›¿æ¢ä¸º SafeClassã€‚"""

    def find_class(self, module, name):
        """å°è¯•æŸ¥æ‰¾ä¸€ä¸ªç±»ï¼Œå¦‚æœä¸åœ¨å®‰å…¨æ¨¡å—ä¸­ï¼Œåˆ™è¿”å› SafeClassã€‚"""
        safe_modules = (
            "torch",
            "collections",
            "collections.abc",
            "builtins",
            "math",
            "numpy",
            # æ·»åŠ å…¶ä»–è¢«è®¤ä¸ºæ˜¯å®‰å…¨çš„æ¨¡å—
        )
        if module in safe_modules:
            return super().find_class(module, name)
        else:
            return SafeClass


def torch_safe_load(weight, safe_only=False):
    """
    å°è¯•ä½¿ç”¨ torch.load() å‡½æ•°åŠ è½½ PyTorch æ¨¡å‹ã€‚å¦‚æœå¼•å‘ ModuleNotFoundErrorï¼Œå°†æ•è·è¯¥é”™è¯¯ï¼Œ
    è®°å½•è­¦å‘Šä¿¡æ¯ï¼Œå¹¶å°è¯•é€šè¿‡ check_requirements() å‡½æ•°å®‰è£…ç¼ºå°‘çš„æ¨¡å—ã€‚
    å®‰è£…åï¼Œå‡½æ•°å†æ¬¡å°è¯•ä½¿ç”¨ torch.load() åŠ è½½æ¨¡å‹ã€‚

    å‚æ•°ï¼š
        weight (str): PyTorch æ¨¡å‹çš„æ–‡ä»¶è·¯å¾„ã€‚
        safe_only (bool): å¦‚æœä¸º Trueï¼Œåœ¨åŠ è½½æ—¶ç”¨ SafeClass æ›¿æ¢æœªçŸ¥ç±»ã€‚

    è¿”å›ï¼š
        ckpt (dict): åŠ è½½çš„æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚
        file (str): åŠ è½½çš„æ–‡ä»¶åã€‚
    """
    file = weight
    try:
        with temporary_modules():
            if safe_only:
                # é€šè¿‡è‡ªå®šä¹‰ pickle æ¨¡å—åŠ è½½
                safe_pickle = types.ModuleType("safe_pickle")
                safe_pickle.Unpickler = SafeUnpickler
                safe_pickle.load = lambda file_obj: SafeUnpickler(file_obj).load()
                with open(file, "rb") as f:
                    ckpt = torch.load(f, pickle_module=safe_pickle)
            else:
                ckpt = torch.load(file, map_location="cpu")

    except ModuleNotFoundError as e:  # e.name æ˜¯ç¼ºå°‘çš„æ¨¡å—åç§°
        check_requirements(e.name)  # å®‰è£…ç¼ºå°‘çš„æ¨¡å—
        ckpt = torch.load(file, map_location="cpu")

    if not isinstance(ckpt, dict):
        # æ–‡ä»¶å¯èƒ½æ˜¯ YOLO å®ä¾‹ï¼Œä½¿ç”¨ i.e. torch.save(model, "saved_model.pt")
        LOGGER.warning(
            f"WARNING âš ï¸ æ–‡ä»¶ '{weight}' ä¼¼ä¹ä¿å­˜æˆ–æ ¼å¼ä¸å½“ã€‚"
            f"ä¸ºäº†è·å¾—æœ€ä½³æ•ˆæœï¼Œè¯·ä½¿ç”¨ model.save('filename.pt') æ­£ç¡®ä¿å­˜ YOLO æ¨¡å‹ã€‚"
        )
        ckpt = {"model": ckpt.model}

    return ckpt, file


class Ensemble(nn.ModuleList):
    """æ¨¡å‹çš„é›†åˆã€‚"""

    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹çš„é›†åˆã€‚"""
        super().__init__()

    def forward(self, x, augment=False, profile=False, visualize=False):
        y = [module(x, augment, profile, visualize)[0] for module in self]
        y = torch.cat(y, 2)  # NMS é›†åˆï¼Œy å½¢çŠ¶ä¸º (B, HW, C)
        return y, None  # æ¨ç†ï¼Œè®­ç»ƒè¾“å‡º


def attempt_load_weights(weights, device=None, inplace=True, fuse=False):
    """åŠ è½½æ¨¡å‹é›†åˆ weights=[a,b,c] æˆ–å•ä¸ªæ¨¡å‹ weights=[a] æˆ– weights=aã€‚"""
    ensemble = Ensemble()
    for w in weights if isinstance(weights, list) else [weights]:
        ckpt, w = torch_safe_load(w)  # åŠ è½½æ£€æŸ¥ç‚¹
        args = {**DEFAULT_CFG_DICT, **ckpt["train_args"]} if "train_args" in ckpt else None  # ç»„åˆå‚æ•°
        model = (ckpt.get("ema") or ckpt["model"]).to(device).float()  # FP32 æ¨¡å‹

        # æ¨¡å‹å…¼å®¹æ€§æ›´æ–°
        model.args = args  # å°†å‚æ•°é™„åŠ åˆ°æ¨¡å‹
        model.pt_path = w  # å°† *.pt æ–‡ä»¶è·¯å¾„é™„åŠ åˆ°æ¨¡å‹
        model.task = guess_model_task(model)
        if not hasattr(model, "stride"):
            model.stride = torch.tensor([32.0])

        # æ·»åŠ åˆ°é›†åˆ
        ensemble.append(model.fuse().eval() if fuse and hasattr(model, "fuse") else model.eval())  # æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼

    # æ¨¡å—æ›´æ–°
    for m in ensemble.modules():
        if hasattr(m, "inplace"):
            m.inplace = inplace
        elif isinstance(m, nn.Upsample) and not hasattr(m, "recompute_scale_factor"):
            m.recompute_scale_factor = None  # å…¼å®¹ torch 1.11.0

    # è¿”å›æ¨¡å‹
    if len(ensemble) == 1:
        return ensemble[-1]

    # è¿”å›é›†åˆ
    LOGGER.info(f"åˆ›å»ºçš„é›†åˆåŒ…å« {weights}\n")
    for k in "names", "nc", "yaml":
        setattr(ensemble, k, getattr(ensemble[0], k))
    ensemble.stride = ensemble[int(torch.argmax(torch.tensor([m.stride.max() for m in ensemble])))].stride
    assert all(ensemble[0].nc == m.nc for m in ensemble), f"æ¨¡å‹ç±»åˆ«æ•°é‡ä¸åŒ {[m.nc for m in ensemble]}"
    return ensemble


def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):
    """åŠ è½½å•ä¸ªæ¨¡å‹æƒé‡ã€‚"""
    ckpt, weight = torch_safe_load(weight)  # åŠ è½½æ£€æŸ¥ç‚¹
    args = {**DEFAULT_CFG_DICT, **(ckpt.get("train_args", {}))}  # ç»„åˆæ¨¡å‹å’Œé»˜è®¤å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨æ¨¡å‹å‚æ•°
    model = (ckpt.get("ema") or ckpt["model"]).to(device).float()  # FP32 æ¨¡å‹

    # æ¨¡å‹å…¼å®¹æ€§æ›´æ–°
    model.args = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # å°†å‚æ•°é™„åŠ åˆ°æ¨¡å‹
    model.pt_path = weight  # å°† *.pt æ–‡ä»¶è·¯å¾„é™„åŠ åˆ°æ¨¡å‹
    model.task = guess_model_task(model)
    if not hasattr(model, "stride"):
        model.stride = torch.tensor([32.0])

    model = model.fuse().eval() if fuse and hasattr(model, "fuse") else model.eval()  # æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼

    # æ¨¡å—æ›´æ–°
    for m in model.modules():
        if hasattr(m, "inplace"):
            m.inplace = inplace
        elif isinstance(m, nn.Upsample) and not hasattr(m, "recompute_scale_factor"):
            m.recompute_scale_factor = None  # å…¼å®¹ torch 1.11.0

    # è¿”å›æ¨¡å‹å’Œæ£€æŸ¥ç‚¹
    return model, ckpt


def parse_model(d, ch, verbose=True):  # model_dict, input_channels(3)
    """å°† YOLO æ¨¡å‹.yaml å­—å…¸è§£æä¸º PyTorch æ¨¡å‹ã€‚"""
    import ast

    # å‚æ•°
    legacy = True  # å‘åå…¼å®¹ v3/v5/v8/v9 æ¨¡å‹
    max_channels = float("inf")
    nc, act, scales = (d.get(x) for x in ("nc", "activation", "scales"))
    depth, width, kpt_shape = (d.get(x, 1.0) for x in ("depth_multiple", "width_multiple", "kpt_shape"))
    if scales:
        scale = d.get("scale")
        if not scale:
            scale = tuple(scales.keys())[0]
            LOGGER.warning(f"WARNING âš ï¸ æœªä¼ é€’æ¨¡å‹ç¼©æ”¾ï¼Œå‡è®¾ scale='{scale}'ã€‚")
        depth, width, max_channels = scales[scale]

    if act:
        Conv.default_act = eval(act)  # é‡æ–°å®šä¹‰é»˜è®¤æ¿€æ´»ï¼Œå³ Conv.default_act = nn.SiLU()
        if verbose:
            LOGGER.info(f"{colorstr('activation:')} {act}")  # æ‰“å°

    if verbose:
        LOGGER.info(f"\n{'':>3}{'from':>20}{'n':>3}{'params':>10}  {'module':<45}{'arguments':<30}")
    ch = [ch]
    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out
    for i, (f, n, m, args) in enumerate(d["backbone"] + d["head"]):  # from, number, module, args
        m = getattr(torch.nn, m[3:]) if "nn." in m else globals()[m]  # è·å–æ¨¡å—
        for j, a in enumerate(args):
            if isinstance(a, str):
                try:
                    args[j] = locals()[a] if a in locals() else ast.literal_eval(a)
                except ValueError:
                    pass
        n = n_ = max(round(n * depth), 1) if n > 1 else n  # æ·±åº¦å¢ç›Š
        if m in {
            Conv,
            ConvTranspose,
            GhostConv,
            Bottleneck,
            GhostBottleneck,
            SPP,
            SPPF,
            C2fPSA,
            C2PSA,
            DWConv,
            Focus,
            BottleneckCSP,
            C1,
            C2,
            C2f,
            C3k2,
            RepNCSPELAN4,
            ELAN1,
            ADown,
            AConv,
            SPPELAN,
            C2fAttn,
            C3,
            C3TR,
            C3Ghost,
            C3x,
            RepC3,
            PSA,
            SCDown,
            C2fCIB,
            C3x,
            nn.ConvTranspose2d,
            DWConvTranspose2d,
        }:
            c1, c2 = ch[f], args[0]
            if c2 != nc:  # å¦‚æœ c2 ä¸ç­‰äºç±»åˆ«æ•°é‡ï¼ˆå³ Classify() è¾“å‡ºï¼‰
                c2 = make_divisible(min(c2, max_channels) * width, 8)
            if m is C2fAttn:
                args[1] = make_divisible(min(args[1], max_channels // 2) * width, 8)  # åµŒå…¥é€šé“
                args[2] = int(
                    max(round(min(args[2], max_channels // 2 // 32)) * width, 1) if args[2] > 1 else args[2]
                )  # num heads

            args = [c1, c2, *args[1:]]
            if m in {
                BottleneckCSP,
                C1,
                C2,
                C2f,
                C3k2,
                C2fAttn,
                C3,
                C3TR,
                C3Ghost,
                C3x,
                RepC3,
                C2fPSA,
                C2fCIB,
                C2PSA,
            }:
                args.insert(2, n)  # é‡å¤æ¬¡æ•°
                n = 1
            if m is C3k2:  # å¯¹äº M/L/X å°ºå¯¸
                legacy = False
                if scale in "mlx":
                    args[3] = True
        elif m is AIFI:
            args = [ch[f], *args]
        elif m in {HGStem, HGBlock}:
            c1, cm, c2 = ch[f], args[0], args[1]
            args = [c1, cm, c2, *args[2:]]
            if m is HGBlock:
                args.insert(4, n)  # é‡å¤æ¬¡æ•°
                n = 1
        elif m is ResNetLayer:
            c2 = args[1] if args[3] else args[1] * 4
        elif m is nn.BatchNorm2d:
            args = [ch[f]]
        elif m is Concat:
            c2 = sum(ch[x] for x in f)
        elif m in {Detect, ImagePoolingAttn}:
            args.append([ch[x] for x in f])
            if m in {Detect}:
                m.legacy = legacy
        elif m is CBLinear:
            c2 = args[0]
            c1 = ch[f]
            args = [c1, c2, *args[1:]]
        elif m is CBFuse:
            c2 = ch[f[-1]]
        else:
            c2 = ch[f]

        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # æ¨¡å—
        t = str(m)[8:-2].replace("__main__.", "")  # æ¨¡å—ç±»å‹
        m_.np = sum(x.numel() for x in m_.parameters())  # å‚æ•°æ•°é‡
        m_.i, m_.f, m_.type = i, f, t  # é™„åŠ ç´¢å¼•ã€'from' ç´¢å¼•ã€ç±»å‹
        if verbose:
            LOGGER.info(f"{i:>3}{str(f):>20}{n_:>3}{m_.np:10.0f}  {t:<45}{str(args):<30}")  # æ‰“å°
        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
        layers.append(m_)
        if i == 0:
            ch = []
        ch.append(c2)
    return nn.Sequential(*layers), sorted(save)


def yaml_model_load(path):
    """ä» YAML æ–‡ä»¶åŠ è½½ YOLOv8 æ¨¡å‹ã€‚"""
    path = Path(path)
    if path.stem in (f"yolov{d}{x}6" for x in "nsmlx" for d in (5, 8)):
        new_stem = re.sub(r"(\d+)([nslmx])6(.+)?$", r"\1\2-p6\3", path.stem)
        LOGGER.warning(f"WARNING âš ï¸ YOLO P6 æ¨¡å‹ç°åœ¨ä½¿ç”¨ -p6 åç¼€ã€‚é‡å‘½å {path.stem} ä¸º {new_stem}ã€‚")
        path = path.with_name(new_stem + path.suffix)

    unified_path = re.sub(r"(\d+)([nslmx])(.+)?$", r"\1\3", str(path))  # å³ yolov8x.yaml -> yolov8.yaml
    yaml_file = unified_path or path
    d = yaml_load(yaml_file)  # æ¨¡å‹å­—å…¸
    d["scale"] = guess_model_scale(path)
    d["yaml_file"] = str(path)
    return d


def guess_model_scale(model_path):
    """
    è·å– YOLO æ¨¡å‹çš„ YAML æ–‡ä»¶è·¯å¾„ä½œä¸ºè¾“å…¥ï¼Œå¹¶æå–æ¨¡å‹ç¼©æ”¾çš„å¤§å°å­—ç¬¦ã€‚è¯¥å‡½æ•°
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åœ¨ YAML æ–‡ä»¶åä¸­æŸ¥æ‰¾æ¨¡å‹ç¼©æ”¾çš„æ¨¡å¼ï¼Œç¼©æ”¾ç”±
    nã€sã€mã€l æˆ– x è¡¨ç¤ºã€‚è¯¥å‡½æ•°è¿”å›æ¨¡å‹ç¼©æ”¾çš„å¤§å°å­—ç¬¦ä½œä¸ºå­—ç¬¦ä¸²ã€‚

    å‚æ•°ï¼š
        model_path (str | Path): YOLO æ¨¡å‹çš„ YAML æ–‡ä»¶è·¯å¾„ã€‚

    è¿”å›ï¼š
        (str): æ¨¡å‹ç¼©æ”¾çš„å¤§å°å­—ç¬¦ï¼Œå¯ä»¥æ˜¯ nã€sã€mã€l æˆ– xã€‚
    """
    try:
        return re.search(r"yolo[v]?\d+([nslmx])", Path(model_path).stem).group(1)  # noqaï¼Œè¿”å› nã€sã€mã€l æˆ– x
    except AttributeError:
        return ""


def guess_model_task(model):
    return "detect"  # å‡è®¾æ˜¯æ£€æµ‹